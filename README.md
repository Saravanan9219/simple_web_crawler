# simple_web_crawler
A Simple Web crawler based on lxml and grequests

Dependencies are included in file dependencies
Using pip install dependencies
     pip install -r dependencies

Example Usage:
python crawler.py

Enter the url: (eg: http://chennaipy.org)
http://chennaipy.org

Enter the number of urls to be crawled (eg: 5)
4

The scrapped pages in found in html_folder
The list of links scrapped is found inside html_folder as links_list.json

